[
["index.html", "Problems and Solutions in Applied Statistics Chapter 1 Introduction", " Problems and Solutions in Applied Statistics Ken Butler 2018-10-09 Chapter 1 Introduction This book will hold a collection of problems, and their solutions, in applied statistics with R. These come from my courses STAC32 and STAD29 at the University of Toronto Scarborough. "],
["getting-used-to-r-and-r-studio.html", "Chapter 2 Getting used to R and R Studio 2.1 Getting started on R Studio Cloud 2.2 Getting used to R Studio 2.3 Data file operations", " Chapter 2 Getting used to R and R Studio We begin with this: library(tidyverse) ## ── Attaching packages ─────────────────────────────────────────────────────────────────────────────────────── tidyverse 1.2.1 ── ## ✔ ggplot2 3.0.0 ✔ purrr 0.2.5 ## ✔ tibble 1.4.2 ✔ dplyr 0.7.6 ## ✔ tidyr 0.8.1 ✔ stringr 1.3.1 ## ✔ readr 1.1.1 ✔ forcats 0.3.0 ## ── Conflicts ────────────────────────────────────────────────────────────────────────────────────────── tidyverse_conflicts() ── ## ✖ dplyr::filter() masks stats::filter() ## ✖ dplyr::lag() masks stats::lag() and so to the problems: 2.1 Getting started on R Studio Cloud Follow these steps to get an R Studio Cloud account. Point your web browser at rstudio.cloud. (If you already have R and R Studio installed on your computer, you can use that instead, throughout the course; just do part (d) of this question. Any references to R Studio Cloud in this assignment also apply to R Studio on your computer.) Solution You should see this: . Click on Get Started. You might instead see the screen in the next part. Choose an account to use. Solution Here’s what you should see now: If you’re happy with using your Google account, click that button. You will probably have to enter your Google password. (If you are doing this on your own computer, you might not have to do that.) If you have a GitHub account and you want to use that, same principle. You can also use an email address as your login to R Studio Cloud. (You can use any e-mail address; I’m not checking.) Enter it in the top box, and enter a password to use with R Studio Cloud in the second. (This does not have to be, and indeed probably should not be, the same as your email password.) Below that, enter your first and last name. This will appear at the top right of the screen when you are logged in. Then click Sign Up. After that, you will have to make a unique account name (which you actually never use, but verb+rstudio.cloud+ uses to name your files). After that, you are automatically logged in. Take a look around, and create a new Project. Give the new project any name you like. Solution This is what you see now: Click on the blue New Project button to create a new Project. (A project is a self-contained piece of work, like for example an assignment.) You will see the words “Loading Project” and spinning circles for a few moments. Then you see this: To give your project a name, click at the top where it says Untitled Project and type a name like Assignment 0 into the box. Before we get to work, look for the blue &gt; at the bottom left. Click next to it to get a flashing cursor, and then type what you see here (in blue): Then press Enter. Solution This lets it install a bunch of things. It may take some time. If you are watching it, look out for lines beginning with g++, which are C++ code that needs to be compiled. This is the end of what I had. Look out for the word DONE near the bottom: Not for now, but for later: if you are on a lab computer, you should probably log out when you are done. To do that, find your name at the top right. Click on it, and two things should pop out to the right: Profile and Log Out. Select Log Out. You should be returned to one of the screens you began with, possibly the Welcome to R Studio Cloud one. To log back in, now or next time, look for Log In at the top right. Click it, to get this: and then you can log in with your email and password, or Google or Github IDs, whichever you used. Now we can get down to some actual work. 2.2 Getting used to R Studio This question is to get you started using R. Start R Studio Cloud, in some project. (If you started up a new project in the previous question and are still logged in, use that; if not, create a new project.) Solution You ought to see something like this. I have a dark blue background here, which you probably do not. It won’t look exactly like that (for example, the background will probably be white) but there should be one thing on the left half, and at the top right it’ll say “Environment is empty”. Extra: if you want to tweak things, select Tools (at the top of the screen) and from it Global Options, then click Appearance. You can make the text bigger or smaller via Editor Font Size, and choose a different colour scheme by picking one of the Editor Themes (which previews on the right). My favourite is Tomorrow Night Blue. Click Apply or OK when you have found something you like. (I spend a lot of time in R Studio, and I like having a dark background to be easier on my eyes.) We’re going to do some stuff in R here, just to get used to it. First, make an R Notebook by selecting File, New File and R Notebook. Solution The first time, you’ll be invited to “install some packages” to make the Notebook thing work. Let it do that by clicking Yes. After that, you’ll have this: Find the Insert and Run buttons along the top of the R Notebook window. We’ll be using them shortly. (The template notebook may or may not be maximized; it doesn’t matter either way. You might see all four panes or as few as one. If you want to control that, select View at the top, then Panes, then either Show All Panes or Zoom Source, as you prefer. In the menus, you’ll also see keyboard shortcuts for these, which you might find worth learning.) Change the title to something of your choosing. Then go down to line 5, click on the Insert button and select R. You should see a “code chunk” appear at line 5, which we are going to use in a moment. Solution Something like this: Type the line of code shown below into the chunk in the R Notebook: mtcars Solution What this will do: get hold of a built-in data set with information about some different models of car, and display it. In approximately five seconds, you’ll be demonstrating that for yourself. Run this command. To do that, look at the top right of your code chunk block (shaded in a slightly different colour). You should see a gear symbol, a down arrow and a green ``play button’’. Click the play button. This will run the code, and show the output below the code chunk. Solution Here’s what I get (yours will be the same). This is a rectangular array of rows and columns, with individuals in rows and variables in columns, known as a “data frame”. When you display a data frame in an R Notebook, you see 10 rows and as many columns as will fit on the screen. At the bottom, it says how many rows and columns there are altogether (here 32 rows and 11 columns), and which ones are being displayed. You can see more rows by clicking on Next, and if there are more columns, you’ll see a little arrow next to the rightmost column (as here next to am) that you can click on to see more columns. Try it and see. Or if you want to go to a particular collection of rows, click one of the numbers between Previous and Next: 1 is rows 1–10, 2 is rows 11–20, and so on. The column on the left without a header (containing the names of the cars) is called “row names”. These have a funny kind of status, kind of a column and kind of not a column; usually, if we need to use the names, we have to put them in a column first. In future solutions, rather than showing you a screenshot, expect me to show you something like this: mtcars ## # A tibble: 32 x 11 ## mpg cyl disp hp drat wt qsec vs am gear carb ## * &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 21 6 160 110 3.9 2.62 16.5 0 1 4 4 ## 2 21 6 160 110 3.9 2.88 17.0 0 1 4 4 ## 3 22.8 4 108 93 3.85 2.32 18.6 1 1 4 1 ## 4 21.4 6 258 110 3.08 3.22 19.4 1 0 3 1 ## 5 18.7 8 360 175 3.15 3.44 17.0 0 0 3 2 ## 6 18.1 6 225 105 2.76 3.46 20.2 1 0 3 1 ## 7 14.3 8 360 245 3.21 3.57 15.8 0 0 3 4 ## 8 24.4 4 147. 62 3.69 3.19 20 1 0 4 2 ## 9 22.8 4 141. 95 3.92 3.15 22.9 1 0 4 2 ## 10 19.2 6 168. 123 3.92 3.44 18.3 1 0 4 4 ## # ... with 22 more rows The top bit is the code, the bottom bit with the ## the output. In this kind of display, you only see the first ten rows (by default). If you don’t see the “play button”, make sure that what you have really is a code chunk. (I often accidentally delete one of the special characters above or below the code chunk). If you can’t figure it out, delete this code chunk and make a new one. Sometimes R Studio gets confused. On the code chunk, the other symbols are the settings for this chunk (you have the choice to display or not display the code or the output or to not actually run the code). The second one, the down arrow, runs all the chunks prior to this one (but not this one). The output has its own little buttons. The first one pops the output out into its own window; the second one shows or hides the output, and the third one deletes the output (so that you have to run the chunk again to get it back). Experiment. You can’t do much damage here. Something a little more interesting: summary obtains a summary of whatever you feed it (the five-number summary plus the mean for numerical variables). Obtain this for our data frame. To do this, create a new code chunk below the previous one, type summary(mtcars) into the code chunk, and run it. Solution This is what you should see: or the other way: summary(mtcars) ## mpg cyl disp hp ## Min. :10.40 Min. :4.000 Min. : 71.1 Min. : 52.0 ## 1st Qu.:15.43 1st Qu.:4.000 1st Qu.:120.8 1st Qu.: 96.5 ## Median :19.20 Median :6.000 Median :196.3 Median :123.0 ## Mean :20.09 Mean :6.188 Mean :230.7 Mean :146.7 ## 3rd Qu.:22.80 3rd Qu.:8.000 3rd Qu.:326.0 3rd Qu.:180.0 ## Max. :33.90 Max. :8.000 Max. :472.0 Max. :335.0 ## drat wt qsec vs ## Min. :2.760 Min. :1.513 Min. :14.50 Min. :0.0000 ## 1st Qu.:3.080 1st Qu.:2.581 1st Qu.:16.89 1st Qu.:0.0000 ## Median :3.695 Median :3.325 Median :17.71 Median :0.0000 ## Mean :3.597 Mean :3.217 Mean :17.85 Mean :0.4375 ## 3rd Qu.:3.920 3rd Qu.:3.610 3rd Qu.:18.90 3rd Qu.:1.0000 ## Max. :4.930 Max. :5.424 Max. :22.90 Max. :1.0000 ## am gear carb ## Min. :0.0000 Min. :3.000 Min. :1.000 ## 1st Qu.:0.0000 1st Qu.:3.000 1st Qu.:2.000 ## Median :0.0000 Median :4.000 Median :2.000 ## Mean :0.4062 Mean :3.688 Mean :2.812 ## 3rd Qu.:1.0000 3rd Qu.:4.000 3rd Qu.:4.000 ## Max. :1.0000 Max. :5.000 Max. :8.000 For the gas mileage column mpg, the mean is bigger than the median, and the largest value is unusually large compared with the others, suggesting a distribution that is skewed to the right. There are 11 numeric (quantitative) variables, so we get the five-number summary plus mean for each one. Categorical variables, if we had any here, would be displayed a different way. (In case you are wondering, the way without screenshots is obtained by my writing a notebook with code chunks and running them, so this output genuinely is obtained by running the code you see.) Let’s make a boxplot of the gas mileage data. This is a “poor man’s boxplot”; we’ll see a nicer-looking way later. To do it this way, make another new code chunk, enter the code boxplot(mtcars$mpg) into it, and run the chunk. Solution This is what you should see: boxplot(mtcars$mpg) The long upper whisker supports our guess from before that the distribution is right-skewed. Some aesthetics to finish with: delete the template notebook (all the stuff you didn’t type below your code chunks and output). Then add some narrative text above and below your code chunks. Above the code chunk is where you say what you are going to do (and maybe why you are doing it), and below is where you say what you conclude from the output you just obtained. Solution My complete R Notebook is at http://www.utsc.utoronto.ca/~butler/c32/a0-notebook-1.Rmd. Take a look at it. I added one extra thing: my variable names have “backticks” around them. You’ll see the effect of this in a moment. Backtick is on the key to the left of 1 and below Esc on your keyboard, along with a “squiggle” symbol that we’ll be using later in the course. Save your notebook (the usual way with File and Save). This saves it on the R Studio Cloud servers (and not on your computer). This means that when you come back to R Studio Cloud later, even from another device, this notebook will still be available to you. Now click Preview. This produces a pretty HTML version of your notebook. Solution Note that the HTML document only contains output from the chunks you’ve run in the notebook, so it’s up to you to run them there first. My HTML document is at http://www.utsc.utoronto.ca/~butler/c32/a0-notebook-1.nb.html. Here’s where you see the effect of the backticks: all the variable names are in typewriter font so that you can see they are variable names and not something else. If you want to try this notebook out yourself, you have a couple of options: (i) make a new R Notebook on R Studio Cloud and copy-paste the contents of my file (it’s just text), or (ii) download my R Notebook onto your computer, and then upload it to R Studio Cloud. Look in the Files pane bottom right, and next to New Folder you should see Upload. Upload the file from wherever it got saved to when you downloaded it. Extra: if you’re feeling ambitious, click the arrow to the right of Preview and select Knit to Word. The button changes to Knit with a ball of wool beside it. Now, when you “knit” the notebook, you get a Word document directly — look for it in the Files pane. If you want to, you can hand this kind of thing in (on later assignments), but you’ll have to do a little work first: first, find it in your Files list, then click the checkbox to the left of it, then click More (with the gear, on the same line as New Folder and Upload), then select Export (and click Download). This will put a copy in your downloads folder on your computer, and you can open it from there. If you’re feeling extra-ambitious, you can try Knit to PDF. This produces something that looks as if it was written in LaTeX, but actually wasn’t. To make this work, if you have a library(tidyverse) line somewhere, as you probably will, find the code chunk it’s in, and make it look like this: ``` library(tidyverse) ``` Then it will work. Extra extra: if you like the keyboard better than the mouse, R Studio has a lot of keyboard shortcuts. Two that are useful now: control-alt-i inserts a code chunk where the cursor is, and control-shift-enter runs the code chunk that the cursor is in, if it is in one. (Mac users, “command” instead of “control” in both cases.) I use these two a lot. Optional extra: practice handing in your previewed R notebook, as if it were an assignment that was worth something. (It is good to get the practice in a low-stakes situation, so that you’ll know what to do next week.) Solution There are two steps: download the HTML file onto your computer, and then handing it in on Quercus. To download: find the HTML file that you want to download in the Files pane bottom right. There should be two files starting with the same thing, eg. test1.Rmd, which is the notebook you wrote, and test1.nb.html, which is the previewed version of it, and is the one you want to download. (The test1 part is the name you chose when you saved it.) Click the checkbox to the left of the HTML file. Now click on More above the bottom-right pane. This pops up a menu from which you choose Export. This will pop up another window called Export Files, where you put the name that the file will have on your computer. (I usually leave the name the same.) Click Download. The file will go to your Downloads folder, or wherever things you download off the web go. Now, to hand it in. Open up Quercus at q.utoronto.ca, log in and navigate to this course. Click Assignments. Click (the title of) Assignment 0. There is a big blue Submit Assignment button top right. Click it. You’ll get a File Upload at the bottom of the screen. Click Choose File and find the HTML file that you downloaded. Click Open (or equivalent on your system). The name of the file should appear next to Choose File. Click Submit Assignment. You’ll see Submitted at the top right. If you want to try this again, you can Re-submit Assignment as many times as you like. (For the real thing, you can use this if you realize you made a mistake in something you submitted. The graders’ instructions, for the real thing, are to grade the last file submitted, so in that case you need to make sure that the last thing submitted includes everything that you want graded. Here, though, it doesn’t matter.) Optional extra. Something more ambitious: make a scatterplot of gas mileage mpg, on the \\(y\\) axis, against horsepower, hp, on the \\(x\\)-axis. Solution That goes like this. I’ll explain the steps below. library(tidyverse) ggplot(mtcars, aes(x=hp, y=mpg))+geom_point() $ %$ %$ This shows a somewhat downward trend, which is what you’d expect, since a larger hp value means a more powerful engine, which will probably consume more gas and get fewer miles per gallon. As for the code: to make a ggplot plot, as we will shortly see in class, you first need a ggplot statement that says what to plot. The first thing in a ggplot is a data frame (mtcars here), and then the aes says that the plot will have hp on the \\(x\\)-axis and mpg on the \\(y\\)-axis, taken from the data frame that you specified. That’s all of the what-to-plot. The last thing is how to plot it; geom_point() says to plot the data values as points. You might like to add a regression line to the plot. That is a matter of adding this to the end of the plotting command: ggplot(mtcars, aes(x=hp, y=mpg))+geom_point()+geom_smooth(method=&quot;lm&quot;) The line definitely goes downhill. Decide for yourself how well you think a line fits these data. 2.3 Data file operations In this question, we read a file from the web and do some descriptive statistics and a graph. This is very like what you will be doing on future assignments, so it’s good to practice it now. Take a look at the data file at https://www.utsc.utoronto.ca/~butler/c32/jumping.txt. These are measurements on 30 rats that were randomly made to do different amounts of jumping by group (we’ll see the details later in the course). The control group did no jumping, and the other groups did “low jumping” and “high jumping”. The first column says which jumping group each rat was in, and the second is the rat’s bone density (the experimenters’ supposition was that more jumping should go with higher bone density). What are the two columns of data separated by? (The fancy word is “delimited”). Solution Exactly one space. This is true all the way down, as you can check. Make a new R Notebook. Leave the first four lines, but get rid of the rest of the template document. Start with a code chunk containing library(tidyverse). Run it. Solution You will get either the same message as before or nothing. (I got nothing because I had already loaded the tidyverse in this session.) Put the URL of the data file in a variable called my_url. Then use read_delim to read in the file. (See solutions for how.) read_delim reads data files where the data values are always separated by the same single character, here a space. Save the data frame in a variable rats. Solution Like this: library(tidyverse) my_url=&quot;https://www.utsc.utoronto.ca/~butler/c32/jumping.txt&quot; rats=read_delim(my_url,&quot; &quot;) ## Parsed with column specification: ## cols( ## group = col_character(), ## density = col_integer() ## ) The second thing in read_delim is the thing that separates the data values. Often when you use read_delim it’ll be a space. Take a look at your data frame, by making a new code chunk and putting the data frame’s name in it (as we did with mtcars). Solution rats ## # A tibble: 30 x 2 ## group density ## &lt;chr&gt; &lt;int&gt; ## 1 Control 611 ## 2 Control 621 ## 3 Control 614 ## 4 Control 593 ## 5 Control 593 ## 6 Control 653 ## 7 Control 600 ## 8 Control 554 ## 9 Control 603 ## 10 Control 569 ## # ... with 20 more rows There are 30 rows and two columns, as there should be. Find the mean bone density for rats that did each amount of jumping. Solution This is something you’ll see a lot: group_by followed by summarize. Reminder: to get that funny thing with the percent signs (called the “pipe symbol”), type control-shift-M (or equivalent on a Mac): rats %&gt;% group_by(group) %&gt;% summarize(m=mean(density)) ## # A tibble: 3 x 2 ## group m ## &lt;chr&gt; &lt;dbl&gt; ## 1 Control 601. ## 2 Highjump 639. ## 3 Lowjump 612. The mean bone density is clearly highest for the high jumping group, and not much different between the low-jumping and control groups. Make a boxplot of bone density for each jumping group. Solution On a boxplot, the groups go across and the values go up and down, so the right syntax is this: ggplot(rats,aes(x=group, y=density))+geom_boxplot() Given the amount of variability, the control and low-jump groups are very similar (with the control group having a couple of outliers), but the high-jump group seems to have a consistently higher bone density than the others. This is more or less in line with what the experimenters were guessing, but it seems that it has to be high jumping to make a difference. You might recognize that this is the kind of data where we would use analysis of variance, which we will do later on in the course: we are comparing several (here three) groups. "],
["reading-in-data.html", "Chapter 3 Reading in data 3.1 Orange juice 3.2 Making soap 3.3 Handling shipments", " Chapter 3 Reading in data 3.1 Orange juice The quality of orange juice produced by a manufacturer (identity unknown) is constantly being monitored. The manufacturer has developed a “sweetness index” for its orange juice, for which a higher value means sweeter juice. Is the sweetness index related to a chemical measure such as the amount of water-soluble pectin (parts per million) in the orange juice? Data were obtained from 24 production runs, and the sweetness and pectin content were measured for each run. The data are in http://www.utsc.utoronto.ca/~butler/c32/ojuice.txt. Open that link up now. You can click on that link just above to open the file. The data values are separated by a space. Use the appropriate Tidyverse function to read the data directly from the course website into a “tibble”. Solution Start with this (almost always): library(tidyverse) ## ── Attaching packages ─────────────────────────────────────────────────────────────────────────────────────── tidyverse 1.2.1 ── ## ✔ ggplot2 3.0.0 ✔ purrr 0.2.5 ## ✔ tibble 1.4.2 ✔ dplyr 0.7.6 ## ✔ tidyr 0.8.1 ✔ stringr 1.3.1 ## ✔ readr 1.1.1 ✔ forcats 0.3.0 ## ── Conflicts ────────────────────────────────────────────────────────────────────────────────────────── tidyverse_conflicts() ── ## ✖ dplyr::filter() masks stats::filter() ## ✖ dplyr::lag() masks stats::lag() The appropriate function, the data values being separated by a space, will be read_delim. Put the URL as the first thing in read_delim, or (better) define it into a variable first:endnote{I say “better” because otherwise the read_delim gets rather long. This way you read it as ``the URL is some long thing that I don’t care about especially, and I what I need to do is to read the data from that URL, separated by spaces.’’} url=&quot;http://www.utsc.utoronto.ca/~butler/c32/ojuice.txt&quot; juice=read_delim(url,&quot; &quot;) ## Parsed with column specification: ## cols( ## run = col_integer(), ## sweetness = col_double(), ## pectin = col_integer() ## ) read_delim (or read_csv or any of the others) tell you what variables were read in, and also tell you about any ``parsing errors’’ where it couldn’t work out what was what. Here, we have three variables, which is entirely consistent with the three columns of data values in the file. read_delim can handle data values separated by any character, not just spaces, but the separating character, known as a “delimiter”, does not have a default, so you have to say what it is, every time. Take a look at what got read in. Do you have data for all 24 runs? Solution Type the name of the data frame in a code chunk (a new one, or add it to the end of the previous one). Because this is actually a “tibble”, which is what read_delim reads in, you’ll only actually see the first 10 lines, but it will tell you how many lines there are altogether, and you can click on the appropriate thing to see the rest of it. juice ## # A tibble: 24 x 3 ## run sweetness pectin ## &lt;int&gt; &lt;dbl&gt; &lt;int&gt; ## 1 1 5.2 220 ## 2 2 5.5 227 ## 3 3 6 259 ## 4 4 5.9 210 ## 5 5 5.8 224 ## 6 6 6 215 ## 7 7 5.8 231 ## 8 8 5.6 268 ## 9 9 5.6 239 ## 10 10 5.9 212 ## # ... with 14 more rows I appear to have all the data. If you want further convincing, click Next a couple of times (on yours) to be sure that the runs go down to number 24. In your data frame, where did the column (variable) names come from? How did R know where to get them from? Solution They came from the top line of the data file, so we didn’t have to specify them. This is the default behaviour of all the read_ functions, so we don’t have to ask for it specially. In fact, if the top line of your data file is not variable names, that’s when you have to say something special. The read_ functions have an option col_names which can either be TRUE (the default), which means “read them in from the top line”, FALSE (“they are not there, so make some up”) or a list of column names to use. You might use the last alternative when the column names that are in the file are not the ones you want to use; in that case, you would also say skip=1 to skip the first line. For example, with file a.txt thus: ## a b ## 1 2 ## 3 4 ## 5 6 you could read the same data but call the columns x and y thus: read_delim(&quot;a.txt&quot;,&quot; &quot;,col_names=c(&quot;x&quot;,&quot;y&quot;),skip=1) ## Parsed with column specification: ## cols( ## x = col_integer(), ## y = col_integer() ## ) ## # A tibble: 3 x 2 ## x y ## &lt;int&gt; &lt;int&gt; ## 1 1 2 ## 2 3 4 ## 3 5 6 The juice manufacturer was interested in whether there was a relationship between sweetness and pectin. To assess this, draw a scatterplot. Does it look as if there is any kind of a relationship? (I think sweetness is the outcome variable and pectin is explanatory, so draw your scatterplot appropriately.) Solution This requires a ggplot plot. You can go back and look at the lecture notes to figure out how to make a scatterplot: the “what to plot” is the \\(x\\)-axis and \\(y\\)-axis variables, with the response on the \\(y\\)-axis (starting with a data frame to get the variables from), and the “how to plot” is geom_point to plot the points: ggplot(juice,aes(x=pectin,y=sweetness))+geom_point() It looks to me as if there is a negative relationship: as pectin goes up, sweetness tends to go down. The trend appears to go top left to bottom right. Having said that, I’m wondering how much of the apparent trend is caused by those two observations bottom right with pectin over 350. If you take those away, the trend seems to me to be a lot less convincing. As an extra, you could add a smooth trend to the plot: ggplot(juice,aes(x=pectin,y=sweetness))+geom_point()+geom_smooth() ## `geom_smooth()` using method = &#39;loess&#39; and formula &#39;y ~ x&#39; The smooth trend is kind of downhill, but not very convincing. 3.2 Making soap A company operates two production lines in a factory for making soap bars. The production lines are labelled A and B. A production line that moves faster may produce more soap, but may possibly also produce more “scrap” (that is, bits of soap that can no longer be made into soap bars and will have to be thrown away). The data are in http://www.utsc.utoronto.ca/~butler/c32/soap.txt. Read the data into R. Display the data. There should be 27 rows. Are there? Solution Read directly from the URL, most easily: url=&quot;http://www.utsc.utoronto.ca/~butler/c32/soap.txt&quot; soap=read_delim(url,&quot; &quot;) ## Parsed with column specification: ## cols( ## case = col_integer(), ## scrap = col_integer(), ## speed = col_integer(), ## line = col_character() ## ) soap ## # A tibble: 27 x 4 ## case scrap speed line ## &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;chr&gt; ## 1 1 218 100 a ## 2 2 248 125 a ## 3 3 360 220 a ## 4 4 351 205 a ## 5 5 470 300 a ## 6 6 394 255 a ## 7 7 332 225 a ## 8 8 321 175 a ## 9 9 410 270 a ## 10 10 260 170 a ## # ... with 17 more rows 27 rows. line, which is either a or b, was correctly deduced to be text. Obtain a histogram of the scrap values, using 10 bins for your histogram. Solution ggplot(soap,aes(x=scrap))+geom_histogram(bins=10) Comment briefly on the shape of the histogram. Is it approximately symmetric, skewed to the left, skewed to the right or something else? (By ``comment briefly’’ I mean “say in a few words why you gave the answer you did.”) Solution I would call this “bimodal”. There are two peaks to the histogram, one around 250 and one around 370, with a very small frequency in between (the bar around 300). Apart from the bimodality, there is no particular evidence for a long tail on either end, so I don’t think you could otherwise call it anything other than symmetric. Having said that (this is going beyond the question), the way a histogram looks can depend on the bins you choose to draw it with. This is 8 bins rather than 10: ggplot(soap,aes(x=scrap))+geom_histogram(bins=8) The middle low-frequency bin has gone, and this one just looks symmetric, with a kind of “flat top”. Make side-by-side boxplots of scrap values for each production line. Solution ggplot(soap,aes(x=line,y=scrap))+geom_boxplot() One categorical, one quantitative variable, so boxplots make sense. Do you think your boxplot says that there are differences in the amount of scrap produced by the two production lines, or not? Explain briefly. Solution I would say that there is a difference between the two production lines, with line A producing an average (median) of about 330 and line B producing a median of about 275. But you could also make the case that, although the medians are rather different, there is a lot of variability and hence a lot of overlap between the two boxplots, and therefore that there is not a “substantial” difference. I would say that either of those answers are good emph{if you back them up with proper reasons}. This is going to be a common theme in this course: I am going to ask you to make a decision and support it, where the reasons you provide are often more important than the decision you make. You might be wondering whether the medians, or means, since there is no serious skewness here and definitely no outliers, are “significantly different”. This is inference, which we will come to later, but a preview looks like this: t.test(scrap~line,data=soap) ## ## Welch Two Sample t-test ## ## data: scrap by line ## t = 1.2493, df = 21.087, p-value = 0.2253 ## alternative hypothesis: true difference in means is not equal to 0 ## 95 percent confidence interval: ## -26.97888 108.21222 ## sample estimates: ## mean in group a mean in group b ## 333.5333 292.9167 They are not: the P-value of 0.22 is not anywhere near as small as 0.05, so we can’t reject the null hypothesis that the two lines have equal mean amount of scrap. Rusty on this stuff? Don’t worry; we’re going to come back to it later in the course. I was also wondering about something else: that bimodal histogram. Could that be explained by the scrap values being two different production lines being mixed together? One way to understand that is to have two separate histograms, one for each line, side by side, which is what facetting does. There is an extra wrinkle here that I explain afterwards: ggplot(soap,aes(x=scrap))+geom_histogram(bins=10)+facet_grid(line~.) I could have used facet_wrap, but that would have put the histograms side by side, and I wanted them one above the other (for ease of comparison, since they’ll be on the same scale). facet_grid is like facet_wrap, but offers you more control over where the facets go: you can arrange them above and below by a variable, or left and right by a variable. Whatever is facetting the plots up and down (on the \\(y\\) axis) goes before the squiggle, and whatever facets them left and right goes after. If there is nothing separating the facets in one direction, here horizontally, the variable is replaced by a dot. In some ways, facet_grid is also less flexible, because the facets have to be arranged up/down or left/right by a variable. That worked here, but if you think back to the Australian athletes, where there were ten different sports, it was facet_wrap that did the right thing, arranging the sports along rows and columns to produce a pleasing display. All right, that bimodality. I was expecting that the scrap values from one line would be centred about one value and the scrap values from the other line would be centred about a different value, with a gap in between. But that’s not what happened at all: the line B values are all over the place, while it’s the line A values that are actually bimodal all by themselves. I’m not sure whether that really means anything, since the data sets are pretty small, but it’s kind of interesting. We started out with the suspicion that if the line was run faster, there would be more scrap. We haven’t assessed this yet. Draw a scatter plot with scrap on the \\(y\\) axis and speed on the \\(x\\) axis. Solution Same mechanism as before: ggplot(soap,aes(x=speed,y=scrap))+geom_point() What do you think is the most important conclusion from your plot of the previous part? Describe your conclusion in the context of the data. Solution There seems to be a pretty evident upward trend, apparently linear, which means that if the speed of the production line is higher, the amount of scrap produced is also higher. My last sentence was meant to remind you that `there is an upward trend'' is *not a complete answer*: we are concerned with what that upward trend tells us about the data. This, in other words, confirms the suspicion expressed in the question, which was therefore a rather large clue: more speed tends to go with more scrap. That was as far as I wanted you to go: there seems to be an association with speed, and there might be an association withlinethat turned out not to be statistically significant. What we haven't done is to assess the relationship between speed and scrap for *each* production line. To do that, we want to plot the scrap-speed points distinguished for each production line.ggplotmakes that easy: you add acolourendnote{If you are concerned about the spelling: the guy who wroteggplotis from New Zealand, where they spell &quot;colour&quot; the same way we do. However, if you want to usecolor=`, that works too.} to say what you want to distinguish by colour. This is two quantitative variables and one categorical variable, if you want to think of it that way: ggplot(soap,aes(x=speed,y=scrap,colour=line))+geom_point() Notice that we get a legend, automatically. What is interesting about this one is the red dots are mostly at the top (for any given speed), and the blue dots are mostly at the bottom. That seems to mean that when we account for speed, there is a difference between lines. I want to show you one more embellishment, which is to put the regression lines on the plot for each group separately. This is where ggplot is so nice, since I just have to add one thing: ggplot(soap,aes(x=speed,y=scrap,colour=line))+ geom_point()+geom_smooth(method=&quot;lm&quot;,se=F) The points and lines have come out in different colours, without our having to think too hard. Both lines show an upward trend, with about the same slope, which means that regardless of line, increasing the speed goes with increasing the scrap by the same amount. The fact that the red line is above the blue one, however, suggests that production line A produces more scrap at the same speed than production line B. From a management point of view, there is an interesting dynamic at work: if you run the production line faster, you’ll produce more bars of soap, but you’ll produce more scrap as well. The crucial thing for the people in the supervisor’s office is how much raw material is used per bar of soap, and if you make the soap bars faster, you might use more raw material, which will eat into your profits (from one angle), but you will also have more bars of soap to sell. Here’s another way to see the same thing. I’m definitely not expecting you to follow the code, but you can admire the result! soap2=soap %&gt;% select(-line) ggplot(soap,aes(x=speed,y=scrap))+ geom_point(data=soap2,colour=&quot;grey&quot;)+ geom_point(aes(colour=line))+facet_wrap(~line) $ The idea is that we plot all the points in grey (to ``put them in the background’’) and then in each plot we plot the points again, coloured, for the group we are looking at: line A in the left, line B on the right. This is another way of seeing that line A has more scrap than line B, given the speed at which the line was being run. (I discovered this technique only yesterday. I think the code is remarkably concise for what it does.) The logic of the code is: begin{itemize} item create a new data frame that contains everything in soap except for line item make a scatter plot of all the points in this new data frame, coloured grey item plot the points again (from the original data frame), coloured by which production line they’re from item produce a separate scatterplot for each production line. end{itemize} The trick about creating the new data frame was to enable plotting of all points regardless of group on each subplot (“facet” in ggplot terminology), as well as the ones that come from that production line. I don’t expect you to be able to follow all the details of the code below, either, but I would like you to try and get the logic. What we do is a regression predicting scrap from two things: speed and production line. The results we get are these: scrap.1=lm(scrap~speed+line,data=soap) summary(scrap.1) ## ## Call: ## lm(formula = scrap ~ speed + line, data = soap) ## ## Residuals: ## Min 1Q Median 3Q Max ## -39.557 -14.161 -0.121 17.518 33.953 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 80.41099 14.54379 5.529 1.10e-05 *** ## speed 1.23074 0.06555 18.775 7.48e-16 *** ## lineb -53.12920 8.21003 -6.471 1.08e-06 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 21.13 on 24 degrees of freedom ## Multiple R-squared: 0.9402, Adjusted R-squared: 0.9352 ## F-statistic: 188.6 on 2 and 24 DF, p-value: 2.104e-15 The P-values for speed and line are the second and third things in the last column, \\(7 times 10^{-16}\\) and \\(1 times 10^{-6}\\) respectively. These are both very strongly significant, in contrast to the two-sample \\(t\\)-test where line was not significant. So does production line make a difference or not? The plot says that it does, and the meaning of model scrap.1 just above is that emph{speed affects scrap when you account for line}, and emph{line affects scrap when you account for speed}. (In the two-sample \\(t\\)-test above we didn’t account for speed at all, since the various speeds were all mixed up.) There is a moral to this story, which I would like you to get even if you don’t get any of the statistics: emph{if a variable makes a difference}, it should be in your model and on your graph,endnote{Meaning that the graph should contain all three variables, speed, scrap and line.} because it enables you to get better (more precise) conclusions about your other variables. Here, there really is a difference between the production lines, but the \\(t\\)-test was too much of a blunt instrument to unearth it (because speed made a difference as well). 3.3 Handling shipments A company called Global Electronics from time to time imports shipments of a certain large part used as a component in several of its products. The size of the shipment varies each time. Each shipment is sent to one of two warehouses (labelled A and B) for handling. The data in http://www.utsc.utoronto.ca/~butler/c32/global.csv show the size of each shipment (in thousands of parts) and the direct cost of handling it, in thousands of dollars. Also shown is the warehouse (A or B) that handled each shipment. Read the data into R and display your data frame. How many rows and columns does it have? Solution If you open the data file in your web browser, it will probably open as a spreadsheet, which is not really very helpful, since then it is not clear what to do with it. You could, I suppose, save it and upload it to R Studio Cloud, but it requires much less brainpower to open it directly from the URL: url=&quot;http://www.utsc.utoronto.ca/~butler/c32/global.csv&quot; shipments=read_csv(url) ## Parsed with column specification: ## cols( ## warehouse = col_character(), ## size = col_integer(), ## cost = col_double() ## ) If you display your data frame and it looks like this, you are good (you can give the data frame any name): shipments ## # A tibble: 10 x 3 ## warehouse size cost ## &lt;chr&gt; &lt;int&gt; &lt;dbl&gt; ## 1 A 225 12.0 ## 2 B 350 14.1 ## 3 A 150 8.93 ## 4 A 200 11.0 ## 5 A 175 10.0 ## 6 A 180 10.1 ## 7 B 325 13.8 ## 8 B 290 13.3 ## 9 B 400 15 ## 10 A 125 7.97 It has 10 rows and 3 columns. You need to say this to get the mark. That is, there were 10 shipments recorded, and for each of them, 3 variables were noted: the size and cost of the shipment, and the warehouse it was handled at. Make a scatterplot of the cost of handling each shipment as it depends on the shipment’s size. Solution The wording of the question says that cost is the response and so belongs on the \\(y\\)-axis. To make the plot, ggplot with an x= and a y= in the aes (the what to plot'' part), and a `geom_point()` after (thehow to plot it’’): ggplot(shipments,aes(x=size,y=cost))+geom_point() As a matter of coding, there are usually two brackets to close after the aes, the one that begins the ggplot and the one that begins the aes. What kind of relationship do you see on the scatterplot? Do you think a straight line would describe it appropriately? Explain briefly. Solution I see an upward trend: a shipment with larger size costs more to handle. If you look carefully at the scatterplot, you see that the cost of handling a small shipment goes up fairly steeply with its size, but the cost of handling a large shipment, while it still increases with size, does not increase so fast. Thus having one straight line to describe the whole relationship would not work so well. The relationship is actually two different straight lines joined end-to-end, which we will explore later, but if you think the relationship is curved, I’ll accept that. The point is to get at the idea that the rate of increase is not constant. When a shipment comes in, the cost of handling it is not known. A decision is made about which warehouse to send it to, and then, after it is handled, the cost is recorded. What do you think determines which warehouse an incoming shipment goes to? Provide a graph to support your answer. Solution The veiled hint in the question is that the decision must depend on size, since it cannot depend on cost. So we have one quantitative variable size and one categorical variable warehouse, which suggests drawing boxplots: ggplot(shipments,aes(x=warehouse,y=size))+geom_boxplot() Well, there’s the answer right there. When the shipment has small size, it goes to warehouse A, and when it’s large, it goes to Warehouse B. We know this because all the shipments smaller than about 250 (thousand parts) went to A and all the shipments larger than that went to B. (If you want to provide a number to delineate “small” and “large”, anything between the largest A, about 225, and the smallest B, about 290, will do.) Another way to think about this is to add something to the scatterplot you drew before. The obvious thing is to make the two warehouses different colours: ggplot(shipments,aes(x=size,y=cost,colour=warehouse))+ geom_point() As a point of technique, you can split lines of code to make them fit on your screen. You can do this as long as emph{the code that ends the line must be incomplete}, so that R knows more is to come. Ending a line with a pipe symbol, or, as here, with one of the pluses in the middle of a ggplot, will work. If you put the plus on the start of the next line, you’ll get a blank plot, because R thinks you’re done plotting. Try it and see. Anyway, this plot tells exactly the same story: the small shipments (in size or cost) go to Warehouse A and the large ones to Warehouse B. But we don’t know cost when the decision is made about which warehouse to send a shipment to, so the decision must be based on size. In the place where I got these data, it said ``larger shipments are sent to Warehouse B, since this warehouse has specialized equipment that provides greater economies of scale for larger shipments’’. That is to say, very large shipments are more expensive to handle, but not as expensive as you might think.endnote{This is the same idea that it costs more to ride the GO bus from UTSC to York U than it does to ride from UTSC to Scarborough Town, but if you work out how much it costs per kilometre, the longer journey costs less per km. As of when I’m writing this, $5.30 for the 7.2 km to Scarborough Town and $6.75 for the 38 km to York. That’s quite an economy of scale, isn’t it?} That makes sense with our scatterplot, because the slope for larger shipments is less than for smaller shipments. When we get to regression later, we’ll see what happens if we fit a straight line to data like these, and how to tell whether we really ought to be able to do better with a different form of relationship. There is also a trick to fit what is called a “piecewise linear regression”, which has one slope for small shipment sizes, a different (smaller) slope for large ones, and joins up in the middle. But that’s well beyond our scope now. "]
]
